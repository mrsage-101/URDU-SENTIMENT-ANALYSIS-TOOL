{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "84853cf0-cfce-474a-a1ad-e0e0d4f0bcf2",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3a231fe6-a10c-43ef-87ce-2b09bfc396a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3a970afb-b73d-4f75-a18e-a29094e7e56b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a1aeb7e-99a6-4614-a225-34484dac96e4",
   "metadata": {},
   "source": [
    "#### load datset from uploaded file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b0f85b9c-3716-4cdd-a112-5fdcc2d2679d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>urdu_text</th>\n",
       "      <th>is_sarcastic</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "      <th>Unnamed: 5</th>\n",
       "      <th>Unnamed: 6</th>\n",
       "      <th>Unnamed: 7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>🤣😂😂 ہو لینے دے میری شادی فسادن ٹھیک ہے کوجی نہ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>چل مہمانوں میں کھانا سرو کر چڑیل چاچی نوں دسدی...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>کامران خان آپکی دن بھریہ زمہ داری لگائی گئی اپ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>نہیں پائین 😎</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>`` مراد علی شاہ کے بھیس میں ڈی جی آئی ایس آئی...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           urdu_text  is_sarcastic  \\\n",
       "0  🤣😂😂 ہو لینے دے میری شادی فسادن ٹھیک ہے کوجی نہ...           1.0   \n",
       "1  چل مہمانوں میں کھانا سرو کر چڑیل چاچی نوں دسدی...           1.0   \n",
       "2  کامران خان آپکی دن بھریہ زمہ داری لگائی گئی اپ...           0.0   \n",
       "3                                       نہیں پائین 😎           0.0   \n",
       "4   `` مراد علی شاہ کے بھیس میں ڈی جی آئی ایس آئی...           1.0   \n",
       "\n",
       "   Unnamed: 2  Unnamed: 3  Unnamed: 4  Unnamed: 5 Unnamed: 6  Unnamed: 7  \n",
       "0         NaN         NaN         NaN         NaN        NaN         NaN  \n",
       "1         NaN         NaN         NaN         NaN        NaN         NaN  \n",
       "2         NaN         NaN         NaN         NaN        NaN         NaN  \n",
       "3         NaN         NaN         NaN         NaN        NaN         NaN  \n",
       "4         NaN         NaN         NaN         NaN        NaN         NaN  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = 'urdu_sarcastic_dataset.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c79d885-c433-46f3-b346-f00e9591892d",
   "metadata": {},
   "source": [
    "## Cleaning the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9a447131-dfea-4aa1-ad04-93267c9bc187",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20060 entries, 0 to 20059\n",
      "Data columns (total 8 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   urdu_text     19955 non-null  object \n",
      " 1   is_sarcastic  20004 non-null  float64\n",
      " 2   Unnamed: 2    0 non-null      float64\n",
      " 3   Unnamed: 3    0 non-null      float64\n",
      " 4   Unnamed: 4    0 non-null      float64\n",
      " 5   Unnamed: 5    0 non-null      float64\n",
      " 6   Unnamed: 6    17 non-null     object \n",
      " 7   Unnamed: 7    38 non-null     float64\n",
      "dtypes: float64(6), object(2)\n",
      "memory usage: 1.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c5f77d9-f6a8-456d-94f4-31d1d718eaa4",
   "metadata": {},
   "source": [
    "#### removing the unamed: 2,3,4,5,6,7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4a4a617c-61c8-4a0d-9b3f-d4b410b849e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20060 entries, 0 to 20059\n",
      "Data columns (total 2 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   urdu_text     19955 non-null  object \n",
      " 1   is_sarcastic  20004 non-null  float64\n",
      "dtypes: float64(1), object(1)\n",
      "memory usage: 313.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df_cleansed = df[['urdu_text', 'is_sarcastic']]\n",
    "df_cleansed.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "54998065-bce3-41ec-a18f-4f7a3ca9aaa3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>urdu_text</th>\n",
       "      <th>is_sarcastic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>🤣😂😂 ہو لینے دے میری شادی فسادن ٹھیک ہے کوجی نہ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>چل مہمانوں میں کھانا سرو کر چڑیل چاچی نوں دسدی...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>کامران خان آپکی دن بھریہ زمہ داری لگائی گئی اپ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>نہیں پائین 😎</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>`` مراد علی شاہ کے بھیس میں ڈی جی آئی ایس آئی...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           urdu_text  is_sarcastic\n",
       "0  🤣😂😂 ہو لینے دے میری شادی فسادن ٹھیک ہے کوجی نہ...           1.0\n",
       "1  چل مہمانوں میں کھانا سرو کر چڑیل چاچی نوں دسدی...           1.0\n",
       "2  کامران خان آپکی دن بھریہ زمہ داری لگائی گئی اپ...           0.0\n",
       "3                                       نہیں پائین 😎           0.0\n",
       "4   `` مراد علی شاہ کے بھیس میں ڈی جی آئی ایس آئی...           1.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cleansed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ccfcd52d-3dc8-4a78-ab53-57f356612e67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_sarcastic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>20004.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.500050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.500012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       is_sarcastic\n",
       "count  20004.000000\n",
       "mean       0.500050\n",
       "std        0.500012\n",
       "min        0.000000\n",
       "25%        0.000000\n",
       "50%        1.000000\n",
       "75%        1.000000\n",
       "max        1.000000"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cleansed.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8229b28a-c9b3-411a-b853-116c441f687f",
   "metadata": {},
   "source": [
    "#### here you can see total rows are 20060\n",
    "#### urdu_text has 19955 out of 20060, they should be taken care of \n",
    "#### same for the is_sarcastic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cc38eb3e-e2bf-4c56-926b-57019517a00b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "urdu_text       105\n",
       "is_sarcastic     56\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cleansed.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "17c4ea97-32ac-46f3-9735-d9049254e2b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20060 entries, 0 to 20059\n",
      "Data columns (total 2 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   urdu_text     19955 non-null  object \n",
      " 1   is_sarcastic  20004 non-null  float64\n",
      "dtypes: float64(1), object(1)\n",
      "memory usage: 313.6+ KB\n"
     ]
    }
   ],
   "source": [
    "# now we have the count we will remove them\n",
    "def_cleansed = df_cleansed.dropna(subset=['urdu_text', 'is_sarcastic'])\n",
    "df_cleansed.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c0377ae-5880-43f8-9a8e-71c368610686",
   "metadata": {},
   "source": [
    "## Step: 1 Text Processing For Urdu\n",
    "### Removal of Stop Words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99810992-bb65-4a39-a2aa-b4e8b1660d39",
   "metadata": {},
   "source": [
    "#### imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "69fea745-aba7-4691-899c-54c2806442fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9c8173bd-8370-4b65-bf09-2323d5de0280",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['کے',\n",
       " 'کا',\n",
       " 'کی',\n",
       " 'ہے',\n",
       " 'ہیں',\n",
       " 'کو',\n",
       " 'میں',\n",
       " 'سے',\n",
       " 'اور',\n",
       " 'پر',\n",
       " 'تھا',\n",
       " 'تھی',\n",
       " 'تھے',\n",
       " 'یہ',\n",
       " 'وہ',\n",
       " 'ایک',\n",
       " 'کچھ',\n",
       " 'لیے',\n",
       " 'جس',\n",
       " 'جن']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urdu_stopwords = [\n",
    "    \"کے\", \"کا\", \"کی\", \"ہے\", \"ہیں\", \"کو\", \"میں\", \"سے\", \"اور\", \"پر\", \"تھا\", \"تھی\", \n",
    "    \"تھے\", \"یہ\", \"وہ\", \"ایک\", \"کچھ\", \"لیے\", \"جس\", \"جن\", \"جو\", \"کہ\", \"نے\", \"بھی\",\n",
    "    \"کر\",\"اگر\", \"تو\", \"جب\", \"تک\", \"تاکہ\", \"جیسا\", \"جیسے\", \"جس\", \"بغیر\", \"ہے\", \"نہیں\",\n",
    "    \"ھے\",\"بھی\",\"کر\",\"آپ\",\"اس\",\"وہ\",\"نہ\",\"اب\",\"جو\",\"جی\",\n",
    "]\n",
    "urdu_stopwords[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "503f85a9-289d-457c-89ef-9752af5acf2f",
   "metadata": {},
   "source": [
    "#### implementing the function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "42a7cd29-3a49-41ee-a24e-30eaa921fa61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>urdu_text</th>\n",
       "      <th>urdu_text_no_stopwords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>🤣😂😂 ہو لینے دے میری شادی فسادن ٹھیک ہے کوجی نہ...</td>\n",
       "      <td>🤣😂😂 ہو لینے دے میری شادی فسادن ٹھیک کوجی چاہیے...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>چل مہمانوں میں کھانا سرو کر چڑیل چاچی نوں دسدی...</td>\n",
       "      <td>چل مہمانوں کھانا سرو چڑیل چاچی نوں دسدی آں میں😂😂</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>کامران خان آپکی دن بھریہ زمہ داری لگائی گئی اپ...</td>\n",
       "      <td>کامران خان آپکی دن بھریہ زمہ داری لگائی گئی اپ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>نہیں پائین 😎</td>\n",
       "      <td>پائین 😎</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>`` مراد علی شاہ کے بھیس میں ڈی جی آئی ایس آئی...</td>\n",
       "      <td>`` مراد علی شاہ بھیس ڈی آئی ایس آئی '' حامد میر😁</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           urdu_text  \\\n",
       "0  🤣😂😂 ہو لینے دے میری شادی فسادن ٹھیک ہے کوجی نہ...   \n",
       "1  چل مہمانوں میں کھانا سرو کر چڑیل چاچی نوں دسدی...   \n",
       "2  کامران خان آپکی دن بھریہ زمہ داری لگائی گئی اپ...   \n",
       "3                                       نہیں پائین 😎   \n",
       "4   `` مراد علی شاہ کے بھیس میں ڈی جی آئی ایس آئی...   \n",
       "\n",
       "                              urdu_text_no_stopwords  \n",
       "0  🤣😂😂 ہو لینے دے میری شادی فسادن ٹھیک کوجی چاہیے...  \n",
       "1   چل مہمانوں کھانا سرو چڑیل چاچی نوں دسدی آں میں😂😂  \n",
       "2  کامران خان آپکی دن بھریہ زمہ داری لگائی گئی اپ...  \n",
       "3                                            پائین 😎  \n",
       "4   `` مراد علی شاہ بھیس ڈی آئی ایس آئی '' حامد میر😁  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=pd.errors.SettingWithCopyWarning)\n",
    "\n",
    "def remove_stopwords(text, stopwords):\n",
    "    # Check if text is a string; if not, return an empty string\n",
    "    if not isinstance(text, str):\n",
    "        return ''\n",
    "    \n",
    "    # Tokenize the text by splitting on spaces\n",
    "    words = text.split()\n",
    "    # Initialize an empty list to store the filtered words\n",
    "    filtered_words = []\n",
    "    # Simple loop to remove words that are in the stopwords list\n",
    "    for word in words:\n",
    "        if word not in stopwords:\n",
    "            filtered_words.append(word)\n",
    "    # Rejoin the filtered words back into a string\n",
    "    return ' '.join(filtered_words)\n",
    "\n",
    "# Applying the stopword removal function to 'urdu_text' column\n",
    "df_cleansed.loc[:, 'urdu_text_no_stopwords'] = df_cleansed['urdu_text'].apply(lambda x: remove_stopwords(x, urdu_stopwords))\n",
    "\n",
    "# Displaying both before and after stopword removal\n",
    "df_cleansed[['urdu_text', 'urdu_text_no_stopwords']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adf7bb78-d235-4493-80ea-5e8a3f4a7901",
   "metadata": {},
   "source": [
    "## Removal of emoji, hashtag, URL, Punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a502e598-00ef-45f6-8447-4ee768c9b11c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting emojiNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "  Using cached emoji-2.13.2-py3-none-any.whl.metadata (5.8 kB)\n",
      "Using cached emoji-2.13.2-py3-none-any.whl (553 kB)\n",
      "Installing collected packages: emoji\n",
      "Successfully installed emoji-2.13.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.1.1 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "07384f77-9583-4603-b50d-6da704a1b81e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2c363aae-12ff-4b9c-8000-2f8984886ac3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>urdu_text_no_stopwords</th>\n",
       "      <th>urdu_text_cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>🤣😂😂 ہو لینے دے میری شادی فسادن ٹھیک کوجی چاہیے...</td>\n",
       "      <td>مثبتمثبتمثبت ہو لینے دے میری شادی فسادن ٹھیک ک...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>چل مہمانوں کھانا سرو چڑیل چاچی نوں دسدی آں میں😂😂</td>\n",
       "      <td>چل مہمانوں کھانا سرو چڑیل چاچی نوں دسدی آں میں...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>کامران خان آپکی دن بھریہ زمہ داری لگائی گئی اپ...</td>\n",
       "      <td>کامران خان آپکی دن بھریہ زمہ داری لگائی گئی اپ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>پائین 😎</td>\n",
       "      <td>پائین مثبت</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>`` مراد علی شاہ بھیس ڈی آئی ایس آئی '' حامد میر😁</td>\n",
       "      <td>`` مراد علی شاہ بھیس ڈی آئی ایس آئی '' حامد میر</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              urdu_text_no_stopwords  \\\n",
       "0  🤣😂😂 ہو لینے دے میری شادی فسادن ٹھیک کوجی چاہیے...   \n",
       "1   چل مہمانوں کھانا سرو چڑیل چاچی نوں دسدی آں میں😂😂   \n",
       "2  کامران خان آپکی دن بھریہ زمہ داری لگائی گئی اپ...   \n",
       "3                                            پائین 😎   \n",
       "4   `` مراد علی شاہ بھیس ڈی آئی ایس آئی '' حامد میر😁   \n",
       "\n",
       "                                   urdu_text_cleaned  \n",
       "0  مثبتمثبتمثبت ہو لینے دے میری شادی فسادن ٹھیک ک...  \n",
       "1  چل مہمانوں کھانا سرو چڑیل چاچی نوں دسدی آں میں...  \n",
       "2  کامران خان آپکی دن بھریہ زمہ داری لگائی گئی اپ...  \n",
       "3                                         پائین مثبت  \n",
       "4    `` مراد علی شاہ بھیس ڈی آئی ایس آئی '' حامد میر  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dictionary to map some common emojis to their sentiment words in Urdu\n",
    "\n",
    "emoji_sentiment_dict = {\n",
    "    \"😂\": \"مثبت\",  # positive\n",
    "    \"🤣\": \"مثبت\",  # positive\n",
    "    \"😊\": \"خوشی\",  # happiness\n",
    "    \"😎\": \"مثبت\",  # positive\n",
    "    \"😡\": \"منفی\",  # negative\n",
    "    \"😢\": \"منفی\",  # negative\n",
    "    \"😭\": \"منفی\",  # negative\n",
    "    \"👍\": \"مثبت\",  # positive\n",
    "    \"👎\": \"منفی\"   # negative\n",
    "}\n",
    "\n",
    "\"\"\"\n",
    "# Dictionary to map some common emojis to their sentiment words in Urdu\n",
    "emoji_sentiment_dict = {\n",
    "    \":face_with_tears_of_joy:\": \"مثبت\",  # 😂\n",
    "    \":rolling_on_the_floor_laughing:\": \"مثبت\",  # 🤣\n",
    "    \":smiling_face_with_smiling_eyes:\": \"خوشی\",  # 😊\n",
    "    \":smiling_face_with_sunglasses:\": \"مثبت\",  # 😎\n",
    "    \":angry_face:\": \"منفی\",  # 😡\n",
    "    \":crying_face:\": \"منفی\",  # 😢\n",
    "    \":loudly_crying_face:\": \"منفی\",  # 😭\n",
    "    \":thumbs_up:\": \"مثبت\",  # 👍\n",
    "    \":thumbs_down:\": \"منفی\"   # 👎\n",
    "}\n",
    "\"\"\"\n",
    "def clean_text(text):\n",
    "    # Remove URLs\n",
    "    text = re.sub(r\"http\\S+|www\\S+|https\\S+\", '', text, flags=re.MULTILINE)\n",
    "    # Remove hashtags and mentions\n",
    "    text = re.sub(r'\\@\\w+|\\#\\w+', '', text)\n",
    "    # Remove punctuation (except for Urdu-specific punctuation)\n",
    "    text = re.sub(r'[!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~]', '', text)\n",
    "    # Replace emojis with sentiment words using the emoji library\n",
    "    #text = emoji.demojize(text)  # Convert emojis to text like :smiling_face_with_smiling_eyes:\n",
    "    for emoji_code, sentiment in emoji_sentiment_dict.items():\n",
    "        text = text.replace(emoji_code, sentiment)  # Replace emoji descriptions with sentiment words\n",
    "    text = emoji.replace_emoji(text, replace='')\n",
    "    return text\n",
    "\n",
    "# Apply the clean_text function to the 'urdu_text_no_stopwords' column\n",
    "df_cleansed['urdu_text_cleaned'] = df_cleansed['urdu_text_no_stopwords'].apply(clean_text)\n",
    "\n",
    "# Display before and after examples of text cleaning\n",
    "df_cleansed[['urdu_text_no_stopwords', 'urdu_text_cleaned']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "864f9056-2f85-49f5-aaeb-5cf062a02e5b",
   "metadata": {},
   "source": [
    "## Removal of Short Posts less than 3 words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "69814dba-718a-42d4-a177-178117dd18b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 19102 entries, 0 to 20003\n",
      "Data columns (total 4 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   urdu_text               19102 non-null  object \n",
      " 1   is_sarcastic            19102 non-null  float64\n",
      " 2   urdu_text_no_stopwords  19102 non-null  object \n",
      " 3   urdu_text_cleaned       19102 non-null  object \n",
      "dtypes: float64(1), object(3)\n",
      "memory usage: 746.2+ KB\n"
     ]
    }
   ],
   "source": [
    "def filtered_short_posts(text):\n",
    "    word_count = len(text.split())\n",
    "    return word_count >= 3\n",
    "\n",
    "df_filtered = df_cleansed[df_cleansed['urdu_text_cleaned'].apply(filtered_short_posts)]\n",
    "df_filtered.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "73c8c658-d78b-40b6-9f4a-6557e74b6ec7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>urdu_text_cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>مثبتمثبتمثبت ہو لینے دے میری شادی فسادن ٹھیک ک...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>چل مہمانوں کھانا سرو چڑیل چاچی نوں دسدی آں میں...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>کامران خان آپکی دن بھریہ زمہ داری لگائی گئی اپ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>`` مراد علی شاہ بھیس ڈی آئی ایس آئی '' حامد میر</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>قابل اعتبار ہی اکثر قاتل اعتبار ہوتے</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   urdu_text_cleaned\n",
       "0  مثبتمثبتمثبت ہو لینے دے میری شادی فسادن ٹھیک ک...\n",
       "1  چل مہمانوں کھانا سرو چڑیل چاچی نوں دسدی آں میں...\n",
       "2  کامران خان آپکی دن بھریہ زمہ داری لگائی گئی اپ...\n",
       "4    `` مراد علی شاہ بھیس ڈی آئی ایس آئی '' حامد میر\n",
       "5              قابل اعتبار ہی اکثر قاتل اعتبار ہوتے "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_filtered[['urdu_text_cleaned']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4edfc469-d96b-4df8-8386-380adb84227c",
   "metadata": {},
   "source": [
    "## Step: 2 Stemming And Lemmitization for Urdu Text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6d2fecf-2c34-40ec-8f5d-fd47a6e300a0",
   "metadata": {},
   "source": [
    "### Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "96fad68c-1607-43e0-8892-23021cb899fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>urdu_text_cleaned</th>\n",
       "      <th>urdu_text_stemmed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19999</th>\n",
       "      <td>راجہ صاحب توڑ سنگ تکر چھڈیا۔۔۔ ہن آواز نئی نکل...</td>\n",
       "      <td>راجہ صاحب توڑ سنگ تکر چھڈیا۔۔۔ ہن آواز نئی نکل...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20000</th>\n",
       "      <td>بعد بےبی پرائم منسٹر بن گئی۔۔مثبتمثبتمثبتمثبت</td>\n",
       "      <td>بعد بےبی پرائم منسٹر بن گئی۔۔مثبتمثبتمثبتمثبت</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20001</th>\n",
       "      <td>اتنا بونگا وزیر اعظم ڈھونڈنے ملے گا</td>\n",
       "      <td>اتنا بونگا وزیر اعظم ڈھونڈنے ملے گ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20002</th>\n",
       "      <td>کاکا تم عِدت پوری ہونے دی  عوام کیسے تیری مدت ...</td>\n",
       "      <td>کاکا تم عِدت پوری ہونے دی عوام کیسے تیری مدت پ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20003</th>\n",
       "      <td>جتنا مرضی بلیک میل لیں این آر او دوں گا،جتنے م...</td>\n",
       "      <td>جتنا مرضی بلیک میل لیں این آر او دوں گا،جتنے م...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       urdu_text_cleaned  \\\n",
       "19999  راجہ صاحب توڑ سنگ تکر چھڈیا۔۔۔ ہن آواز نئی نکل...   \n",
       "20000      بعد بےبی پرائم منسٹر بن گئی۔۔مثبتمثبتمثبتمثبت   \n",
       "20001               اتنا بونگا وزیر اعظم ڈھونڈنے ملے گا    \n",
       "20002  کاکا تم عِدت پوری ہونے دی  عوام کیسے تیری مدت ...   \n",
       "20003  جتنا مرضی بلیک میل لیں این آر او دوں گا،جتنے م...   \n",
       "\n",
       "                                       urdu_text_stemmed  \n",
       "19999  راجہ صاحب توڑ سنگ تکر چھڈیا۔۔۔ ہن آواز نئی نکل...  \n",
       "20000      بعد بےبی پرائم منسٹر بن گئی۔۔مثبتمثبتمثبتمثبت  \n",
       "20001                 اتنا بونگا وزیر اعظم ڈھونڈنے ملے گ  \n",
       "20002  کاکا تم عِدت پوری ہونے دی عوام کیسے تیری مدت پ...  \n",
       "20003  جتنا مرضی بلیک میل لیں این آر او دوں گا،جتنے م...  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dictionary for stemming\n",
    "stemming_dict = {\n",
    "    'ہے': 'ہ',\n",
    "    'ہیں': 'ہ',\n",
    "    'تھا': 'ہ',\n",
    "    'ہوں': 'ہ',\n",
    "    'ہو': 'ہ',\n",
    "    'کر': 'کر',\n",
    "    'کیا': 'کر',\n",
    "    'کریں': 'کر',\n",
    "    'گا': 'گ',\n",
    "    'گیا': 'گ',\n",
    "    'رہے': 'رہ',\n",
    "    'رہا': 'رہ',\n",
    "    'پر': 'پر',\n",
    "    'سے': 'سے',\n",
    "    'میں': 'میں',\n",
    "    'کو': 'کو',\n",
    "    'کہ': 'کہ',\n",
    "    'بھی': 'بھی',\n",
    "    'تو': 'تو',\n",
    "    'ہی': 'ہ',\n",
    "    'نہ': 'نہ',\n",
    "    'یا': 'یا',\n",
    "    # Add more mappings as needed\n",
    "}\n",
    "\n",
    "# A function for simple rule-based stemming using the stemming dictionary\n",
    "def urdu_stemmer(word):\n",
    "    return stemming_dict.get(word, word)  # Return the stemmed word if it exists, else return the word itself\n",
    "\n",
    "# Apply the stemmer to each word in the cleaned text\n",
    "def stem_text(text):\n",
    "    words = text.split()\n",
    "    stemmed_words = [urdu_stemmer(word) for word in words]\n",
    "    return ' '.join(stemmed_words)\n",
    "\n",
    "# Apply the stemming function to the 'urdu_text_cleaned' column\n",
    "df_filtered['urdu_text_stemmed'] = df_filtered['urdu_text_cleaned'].apply(stem_text)\n",
    "\n",
    "# Display before and after examples of stemming\n",
    "df_filtered[['urdu_text_cleaned', 'urdu_text_stemmed']].tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d6d608d4-7b53-43e2-9baa-302d5a681607",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>urdu_text_cleaned</th>\n",
       "      <th>urdu_text_stemmed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>مثبتمثبتمثبت ہو لینے دے میری شادی فسادن ٹھیک ک...</td>\n",
       "      <td>مثبتمثبتمثبت ہ لینے دے میری شادی فسادن ٹھیک کو...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>چل مہمانوں کھانا سرو چڑیل چاچی نوں دسدی آں میں...</td>\n",
       "      <td>چل مہمانوں کھانا سرو چڑیل چاچی نوں دسدی آں میں...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>کامران خان آپکی دن بھریہ زمہ داری لگائی گئی اپ...</td>\n",
       "      <td>کامران خان آپکی دن بھریہ زمہ داری لگائی گئی اپ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>`` مراد علی شاہ بھیس ڈی آئی ایس آئی '' حامد میر</td>\n",
       "      <td>`` مراد علی شاہ بھیس ڈی آئی ایس آئی '' حامد میر</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>قابل اعتبار ہی اکثر قاتل اعتبار ہوتے</td>\n",
       "      <td>قابل اعتبار ہ اکثر قاتل اعتبار ہوتے</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   urdu_text_cleaned  \\\n",
       "0  مثبتمثبتمثبت ہو لینے دے میری شادی فسادن ٹھیک ک...   \n",
       "1  چل مہمانوں کھانا سرو چڑیل چاچی نوں دسدی آں میں...   \n",
       "2  کامران خان آپکی دن بھریہ زمہ داری لگائی گئی اپ...   \n",
       "4    `` مراد علی شاہ بھیس ڈی آئی ایس آئی '' حامد میر   \n",
       "5              قابل اعتبار ہی اکثر قاتل اعتبار ہوتے    \n",
       "\n",
       "                                   urdu_text_stemmed  \n",
       "0  مثبتمثبتمثبت ہ لینے دے میری شادی فسادن ٹھیک کو...  \n",
       "1  چل مہمانوں کھانا سرو چڑیل چاچی نوں دسدی آں میں...  \n",
       "2  کامران خان آپکی دن بھریہ زمہ داری لگائی گئی اپ...  \n",
       "4    `` مراد علی شاہ بھیس ڈی آئی ایس آئی '' حامد میر  \n",
       "5                قابل اعتبار ہ اکثر قاتل اعتبار ہوتے  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_filtered[['urdu_text_cleaned', 'urdu_text_stemmed']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76f91b6c-1a3a-4518-b41d-b1bad8ce6aa4",
   "metadata": {},
   "source": [
    "### Lemmitization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e83e48d8-84e3-4670-ac92-7ab4758d42ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>urdu_text_stemmed</th>\n",
       "      <th>urdu_text_lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>مثبتمثبتمثبت ہ لینے دے میری شادی فسادن ٹھیک کو...</td>\n",
       "      <td>مثبتمثبتمثبت ہ لینے دے میری شادی فسادن ٹھیک کو...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>چل مہمانوں کھانا سرو چڑیل چاچی نوں دسدی آں میں...</td>\n",
       "      <td>چل مہمانوں کھانا سرو چڑیل چاچی نوں دسدی آں میں...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>کامران خان آپکی دن بھریہ زمہ داری لگائی گئی اپ...</td>\n",
       "      <td>کامران خان آپکی دن بھریہ زمہ داری لگا جانا اپو...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>`` مراد علی شاہ بھیس ڈی آئی ایس آئی '' حامد میر</td>\n",
       "      <td>`` مراد علی شاہ بھیس ڈی آئی ایس آئی '' حامد میر</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>قابل اعتبار ہ اکثر قاتل اعتبار ہوتے</td>\n",
       "      <td>قابل اعتبار ہ اکثر قاتل اعتبار ہونا</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   urdu_text_stemmed  \\\n",
       "0  مثبتمثبتمثبت ہ لینے دے میری شادی فسادن ٹھیک کو...   \n",
       "1  چل مہمانوں کھانا سرو چڑیل چاچی نوں دسدی آں میں...   \n",
       "2  کامران خان آپکی دن بھریہ زمہ داری لگائی گئی اپ...   \n",
       "4    `` مراد علی شاہ بھیس ڈی آئی ایس آئی '' حامد میر   \n",
       "5                قابل اعتبار ہ اکثر قاتل اعتبار ہوتے   \n",
       "\n",
       "                                urdu_text_lemmatized  \n",
       "0  مثبتمثبتمثبت ہ لینے دے میری شادی فسادن ٹھیک کو...  \n",
       "1  چل مہمانوں کھانا سرو چڑیل چاچی نوں دسدی آں میں...  \n",
       "2  کامران خان آپکی دن بھریہ زمہ داری لگا جانا اپو...  \n",
       "4    `` مراد علی شاہ بھیس ڈی آئی ایس آئی '' حامد میر  \n",
       "5                قابل اعتبار ہ اکثر قاتل اعتبار ہونا  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Function to apply lemmatization based on the dictionary\n",
    "def lemmatize_text(text, lemmatization_dict):\n",
    "    words = text.split()\n",
    "    # Replace words based on lemmatization dictionary\n",
    "    lemmatized_words = [lemmatization_dict.get(word, word) for word in words]\n",
    "    return ' '.join(lemmatized_words)\n",
    "\n",
    "# Dictionary for lemmatization\n",
    "lemmatization_dict = {\n",
    "    'یہ': 'یہ',\n",
    "    'آپ': 'آپ',\n",
    "    'وہ': 'وہ',\n",
    "    'ہم': 'ہم',\n",
    "    'تم': 'تو',\n",
    "    'ان': 'ان',\n",
    "    'کسی': 'کس',\n",
    "    'اللہ': 'اللہ',\n",
    "    'خان': 'خان',\n",
    "    'بات': 'بات',\n",
    "    'صاحب': 'صاحب',\n",
    "    'پاکستان': 'پاکستان',\n",
    "    'سندھ': 'سندھ',\n",
    "    'اب': 'اب',\n",
    "    'بہت': 'بہ',\n",
    "    'سب': 'سب',\n",
    "    'کوئی': 'کوئی',\n",
    "    'اور': 'اور',\n",
    "    'کا': 'ک',\n",
    "    'کی': 'ک',\n",
    "    'کے': 'ک',\n",
    "    # New additions\n",
    "    'گئی': 'جانا',\n",
    "    'لگائی': 'لگا',\n",
    "    'ہوتے': 'ہونا',\n",
    "    'کرنا': 'کر',\n",
    "    'کہا': 'کہنا',\n",
    "    'پائین': 'پانا',\n",
    "    'جاتی': 'جانا',\n",
    "    'بنائی': 'بننا'\n",
    "}\n",
    "\n",
    "# Apply the lemmatization function to the 'urdu_text_stemmed' column\n",
    "df_filtered['urdu_text_lemmatized'] = df_filtered['urdu_text_stemmed'].apply(lambda x: lemmatize_text(x, lemmatization_dict))\n",
    "\n",
    "# Display before and after examples of lemmatization\n",
    "df_filtered[['urdu_text_stemmed', 'urdu_text_lemmatized']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "00420df5-a705-4e84-a353-95e65b553190",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>urdu_text_stemmed</th>\n",
       "      <th>urdu_text_lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19999</th>\n",
       "      <td>راجہ صاحب توڑ سنگ تکر چھڈیا۔۔۔ ہن آواز نئی نکل...</td>\n",
       "      <td>راجہ صاحب توڑ سنگ تکر چھڈیا۔۔۔ ہن آواز نئی نکل...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20000</th>\n",
       "      <td>بعد بےبی پرائم منسٹر بن گئی۔۔مثبتمثبتمثبتمثبت</td>\n",
       "      <td>بعد بےبی پرائم منسٹر بن گئی۔۔مثبتمثبتمثبتمثبت</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20001</th>\n",
       "      <td>اتنا بونگا وزیر اعظم ڈھونڈنے ملے گ</td>\n",
       "      <td>اتنا بونگا وزیر اعظم ڈھونڈنے ملے گ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20002</th>\n",
       "      <td>کاکا تم عِدت پوری ہونے دی عوام کیسے تیری مدت پ...</td>\n",
       "      <td>کاکا تو عِدت پوری ہونے دی عوام کیسے تیری مدت پ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20003</th>\n",
       "      <td>جتنا مرضی بلیک میل لیں این آر او دوں گا،جتنے م...</td>\n",
       "      <td>جتنا مرضی بلیک میل لیں این آر او دوں گا،جتنے م...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       urdu_text_stemmed  \\\n",
       "19999  راجہ صاحب توڑ سنگ تکر چھڈیا۔۔۔ ہن آواز نئی نکل...   \n",
       "20000      بعد بےبی پرائم منسٹر بن گئی۔۔مثبتمثبتمثبتمثبت   \n",
       "20001                 اتنا بونگا وزیر اعظم ڈھونڈنے ملے گ   \n",
       "20002  کاکا تم عِدت پوری ہونے دی عوام کیسے تیری مدت پ...   \n",
       "20003  جتنا مرضی بلیک میل لیں این آر او دوں گا،جتنے م...   \n",
       "\n",
       "                                    urdu_text_lemmatized  \n",
       "19999  راجہ صاحب توڑ سنگ تکر چھڈیا۔۔۔ ہن آواز نئی نکل...  \n",
       "20000      بعد بےبی پرائم منسٹر بن گئی۔۔مثبتمثبتمثبتمثبت  \n",
       "20001                 اتنا بونگا وزیر اعظم ڈھونڈنے ملے گ  \n",
       "20002  کاکا تو عِدت پوری ہونے دی عوام کیسے تیری مدت پ...  \n",
       "20003  جتنا مرضی بلیک میل لیں این آر او دوں گا،جتنے م...  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_filtered[['urdu_text_stemmed', 'urdu_text_lemmatized']].tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb70fad9-8343-4549-b029-261a8885f738",
   "metadata": {},
   "source": [
    "## Feature Extraction from Text "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "313d6b02-97e3-4d73-b1da-46cfd867d561",
   "metadata": {},
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dc363f00-95d8-45a7-a176-72e68124d0d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\hatee\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4d4cacc9-d82c-4e16-ba15-5d3ba83d4b5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>urdu_text_lemmatized</th>\n",
       "      <th>urdu_text_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>مثبتمثبتمثبت ہ لینے دے میری شادی فسادن ٹھیک کو...</td>\n",
       "      <td>[مثبتمثبتمثبت, ہ, لینے, دے, میری, شادی, فسادن,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>چل مہمانوں کھانا سرو چڑیل چاچی نوں دسدی آں میں...</td>\n",
       "      <td>[چل, مہمانوں, کھانا, سرو, چڑیل, چاچی, نوں, دسد...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>کامران خان آپکی دن بھریہ زمہ داری لگا جانا اپو...</td>\n",
       "      <td>[کامران, خان, آپکی, دن, بھریہ, زمہ, داری, لگا,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>`` مراد علی شاہ بھیس ڈی آئی ایس آئی '' حامد میر</td>\n",
       "      <td>[``, مراد, علی, شاہ, بھیس, ڈی, آئی, ایس, آئی, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>قابل اعتبار ہ اکثر قاتل اعتبار ہونا</td>\n",
       "      <td>[قابل, اعتبار, ہ, اکثر, قاتل, اعتبار, ہونا]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                urdu_text_lemmatized  \\\n",
       "0  مثبتمثبتمثبت ہ لینے دے میری شادی فسادن ٹھیک کو...   \n",
       "1  چل مہمانوں کھانا سرو چڑیل چاچی نوں دسدی آں میں...   \n",
       "2  کامران خان آپکی دن بھریہ زمہ داری لگا جانا اپو...   \n",
       "4    `` مراد علی شاہ بھیس ڈی آئی ایس آئی '' حامد میر   \n",
       "5                قابل اعتبار ہ اکثر قاتل اعتبار ہونا   \n",
       "\n",
       "                                    urdu_text_tokens  \n",
       "0  [مثبتمثبتمثبت, ہ, لینے, دے, میری, شادی, فسادن,...  \n",
       "1  [چل, مہمانوں, کھانا, سرو, چڑیل, چاچی, نوں, دسد...  \n",
       "2  [کامران, خان, آپکی, دن, بھریہ, زمہ, داری, لگا,...  \n",
       "4  [``, مراد, علی, شاہ, بھیس, ڈی, آئی, ایس, آئی, ...  \n",
       "5        [قابل, اعتبار, ہ, اکثر, قاتل, اعتبار, ہونا]  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tokenization function using NLTK\n",
    "def tokenize_text(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    return tokens\n",
    "\n",
    "# Apply tokenization to the 'urdu_text_lemmatized' column\n",
    "df_filtered['urdu_text_tokens'] = df_filtered['urdu_text_lemmatized'].apply(tokenize_text)\n",
    "\n",
    "# Display tokenized examples\n",
    "df_filtered[['urdu_text_lemmatized', 'urdu_text_tokens']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90c129f4-3023-40be-8c40-9ab44946623f",
   "metadata": {},
   "source": [
    "## TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fd37b616-6a9a-402e-9a97-9fe48752cbc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4a784538-1815-48b1-972f-1ec61f7eddbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13209</th>\n",
       "      <td>مثبت</td>\n",
       "      <td>375.688422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19010</th>\n",
       "      <td>کر</td>\n",
       "      <td>365.657218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8797</th>\n",
       "      <td>رہ</td>\n",
       "      <td>244.686340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21746</th>\n",
       "      <td>ہے</td>\n",
       "      <td>208.660022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13229</th>\n",
       "      <td>مثبتمثبت</td>\n",
       "      <td>196.127390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2538</th>\n",
       "      <td>اللہ</td>\n",
       "      <td>175.969492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19583</th>\n",
       "      <td>کوئی</td>\n",
       "      <td>173.319169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19322</th>\n",
       "      <td>کس</td>\n",
       "      <td>171.979700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7141</th>\n",
       "      <td>خان</td>\n",
       "      <td>168.910178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13240</th>\n",
       "      <td>مثبتمثبتمثبت</td>\n",
       "      <td>165.919170</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               word       score\n",
       "13209          مثبت  375.688422\n",
       "19010            کر  365.657218\n",
       "8797             رہ  244.686340\n",
       "21746            ہے  208.660022\n",
       "13229      مثبتمثبت  196.127390\n",
       "2538           اللہ  175.969492\n",
       "19583          کوئی  173.319169\n",
       "19322            کس  171.979700\n",
       "7141            خان  168.910178\n",
       "13240  مثبتمثبتمثبت  165.919170"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize the TfidfVectorizer with a reduced feature set\n",
    "tfidf_vectorizer_reduced = TfidfVectorizer()\n",
    "\n",
    "# Combine the tokenized words back into sentences for the TF-IDF vectorizer\n",
    "df_filtered['urdu_text_for_tfidf'] = df_filtered['urdu_text_tokens'].apply(lambda x: ' '.join(x))\n",
    "\n",
    "# Fit and transform the text data to compute TF-IDF scores with reduced features\n",
    "tfidf_matrix_reduced = tfidf_vectorizer_reduced.fit_transform(df_filtered['urdu_text_for_tfidf'])\n",
    "\n",
    "# Get feature names (words) and their respective TF-IDF scores\n",
    "tfidf_feature_names_reduced = tfidf_vectorizer_reduced.get_feature_names_out()\n",
    "tfidf_scores_reduced = tfidf_matrix_reduced.toarray()\n",
    "\n",
    "# Sum TF-IDF scores across all documents for each feature (word)\n",
    "word_scores_reduced = tfidf_scores_reduced.sum(axis=0)\n",
    "\n",
    "# Create a DataFrame to sort and display top terms by their TF-IDF scores\n",
    "tfidf_df_reduced = pd.DataFrame({'word': tfidf_feature_names_reduced, 'score': word_scores_reduced})\n",
    "tfidf_top_words_reduced = tfidf_df_reduced.sort_values(by='score', ascending=False).head(10)\n",
    "\n",
    "# Display the top 10 words with highest TF-IDF scores\n",
    "tfidf_top_words_reduced\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9e7c568-1d68-4be4-a50c-531d2a9f5d87",
   "metadata": {},
   "source": [
    "## Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3ef954c2-208c-4e17-bc06-9d52df802942",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim in c:\\users\\hatee\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (4.3.3)\n",
      "Requirement already satisfied: numpy<2.0,>=1.18.5 in c:\\users\\hatee\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gensim) (1.26.4)\n",
      "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in c:\\users\\hatee\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gensim) (1.12.0)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in c:\\users\\hatee\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gensim) (7.0.4)\n",
      "Requirement already satisfied: wrapt in c:\\users\\hatee\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from smart-open>=1.8.1->gensim) (1.14.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.1.1 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "807857ee-cb07-4360-821b-e1447992cc00",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install --upgrade scipy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a01bf955-6bd2-4d68-9e3c-bcdd98f01be8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('بلاک', 0.9905962347984314),\n",
       " ('سوار', 0.9902935028076172),\n",
       " ('درد', 0.9901655912399292),\n",
       " ('بہتر', 0.9896510243415833),\n",
       " ('مثبتمثبتمثبتمثبتمثبتمثبتمثبت', 0.9896172881126404)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from gensim.models import Word2Vec \n",
    "\n",
    "# Apply the lemmatization function to the 'urdu_text_stemmed' column\n",
    "df_filtered['urdu_text_lemmatized'] = df_filtered['urdu_text_stemmed'].apply(lambda x: lemmatize_text(x, lemmatization_dict))\n",
    "\n",
    "# Tokenization function using NLTK\n",
    "def tokenize_text(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    return tokens\n",
    "\n",
    "# Apply tokenization to the 'urdu_text_lemmatized' column\n",
    "df_filtered['urdu_text_tokens'] = df_filtered['urdu_text_lemmatized'].apply(tokenize_text)\n",
    "\n",
    "# Prepare the tokenized text data for Word2Vec\n",
    "tokenized_sentences = df_filtered['urdu_text_tokens'].tolist()\n",
    "\n",
    "# Train the Word2Vec model\n",
    "w2v_model = Word2Vec(sentences=tokenized_sentences, vector_size=100, window=5, min_count=2, workers=4, sg=0)\n",
    "\n",
    "# Find the top 5 words most similar to \"اچھا\" (good)\n",
    "try:\n",
    "    similar_words = w2v_model.wv.most_similar(\"اچھا\", topn=5)\n",
    "except KeyError:\n",
    "    similar_words = \"The word 'اچھا' was not found in the vocabulary.\"\n",
    "\n",
    "similar_words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1d512db",
   "metadata": {},
   "source": [
    "### N-GRAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "26d87000",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([(('عمران', 'خان'), 494),\n",
       "  (('نواز', 'شریف'), 442),\n",
       "  (('سندھ', 'پولیس'), 299),\n",
       "  (('ہ', 'گ'), 260),\n",
       "  (('آرمی', 'چیف'), 223),\n",
       "  (('خان', 'صاحب'), 179),\n",
       "  (('کیپٹن', 'صفدر'), 177),\n",
       "  (('مثبت', 'مثبت'), 166),\n",
       "  (('مریم', 'نواز'), 157),\n",
       "  (('جزاک', 'اللہ'), 156)],\n",
       " [(('پی', 'ٹی', 'آئی'), 114),\n",
       "  (('صلی', 'اللہ', 'علیہ'), 87),\n",
       "  (('پی', 'ڈی', 'ایم'), 86),\n",
       "  (('مثبت', 'مثبت', 'مثبت'), 85),\n",
       "  (('جزاک', 'اللہ', 'خیر'), 70),\n",
       "  (('فالو', 'کر', 'فالو'), 69),\n",
       "  (('کر', 'فالو', 'بیک'), 63),\n",
       "  (('والوں', 'فالو', 'کر'), 60),\n",
       "  (('ایس', 'ایچ', 'او'), 55),\n",
       "  (('فالورز', 'اضافہ', 'کر'), 53)])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.util import ngrams\n",
    "from collections import Counter\n",
    "\n",
    "# Function to generate n-grams and calculate their frequencies\n",
    "def generate_ngrams(tokens, n):\n",
    "    return list(ngrams(tokens, n))\n",
    "\n",
    "# Collect all tokens for n-grams analysis\n",
    "all_tokens = df_filtered['urdu_text_tokens'].tolist()\n",
    "\n",
    "# Flatten the list of token lists into a single list of tokens\n",
    "flattened_tokens = [token for tokens in all_tokens for token in tokens]\n",
    "\n",
    "# Generate bigrams and trigrams\n",
    "bigrams = generate_ngrams(flattened_tokens, 2)\n",
    "trigrams = generate_ngrams(flattened_tokens, 3)\n",
    "\n",
    "# Calculate frequencies of bigrams and trigrams\n",
    "bigram_freq = Counter(bigrams)\n",
    "trigram_freq = Counter(trigrams)\n",
    "\n",
    "# Get the top 10 most common bigrams and trigrams\n",
    "top_10_bigrams = bigram_freq.most_common(10)\n",
    "top_10_trigrams = trigram_freq.most_common(10)\n",
    "\n",
    "# Display the top 10 bigrams and trigrams along with their counts\n",
    "top_10_bigrams, top_10_trigrams\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "78bf969b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.75      0.75      0.75      1848\n",
      "         1.0       0.76      0.76      0.76      1973\n",
      "\n",
      "    accuracy                           0.76      3821\n",
      "   macro avg       0.76      0.76      0.76      3821\n",
      "weighted avg       0.76      0.76      0.76      3821\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Step 1: Prepare Data for Modeling\n",
    "# Use TF-IDF features\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=1000)\n",
    "X_tfidf = tfidf_vectorizer.fit_transform(df_filtered['urdu_text_lemmatized'])\n",
    "\n",
    "# Target variable\n",
    "y = df_filtered['is_sarcastic']\n",
    "\n",
    "# Step 2: Split Data into Training and Test Sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_tfidf, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 3: Train the Model\n",
    "# Use Logistic Regression as the classifier\n",
    "model = LogisticRegression(max_iter=200)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Step 4: Evaluate the Model\n",
    "# Predict on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate accuracy, precision, recall, and F1-score\n",
    "classification_report_result = classification_report(y_test, y_pred)\n",
    "confusion_matrix_result = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(classification_report_result)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
